#get bash
docker exec -it namenode bash

#deleting file
hadoop fs -rm /CC/Q2/reducer2.py

#ls 
hdfs dfs -ls /user/root/input/

#adding file to hadoop
docker cp mapper3.py namenode:test/mapper3.py
docker cp mapper.py namenode:
docker cp reducer.py namenode:reducer.py

#putting in folder
hadoop fs -put mapper.py /user/root/input/
hadoop fs -put reducer.py /user/root/input/

#running
hadoop jar /opt/hadoop-3.2.1/share/hadoop/tools/lib/hadoop-streaming-3.2.1.jar \
    -file  mapper.py \
    -mapper "python3 mapper.py" \
    -file  reducer.py\
    -reducer "python3 reducer.py" \
    -input /user/root/input/dataset.csv \
    -output /e1/output \

hadoop jar /opt/hadoop-3.2.1/share/hadoop/tools/lib/hadoop-streaming-3.2.1.jar \
    -file  mapper2.py \
    -mapper "python3 mapper2.py" \
    -file  reducer2.py\
    -reducer "python3 reducer2.py" \
    -input /user/root/input/dataset.csv \
    -output /e2/output \

hadoop jar /opt/hadoop-3.2.1/share/hadoop/tools/lib/hadoop-streaming-3.2.1.jar \
    -file  mapper3.py \
    -mapper "python3 mapper3.py" \
    -file  reducer3.py\
    -reducer "python3 reducer3.py" \
    -input /user/root/input/dataset.csv \
    -output /test/output \


#jar
/opt/hadoop-3.2.1/share/hadoop/tools/lib/hadoop-streaming-3.2.1.jar

#output
hdfs dfs -cat /e1/output/part-00000
