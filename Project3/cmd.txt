#get bash
docker exec -it namenode bash

#deleting file
hadoop fs -rm /CC/Q2/reducer2.py

#ls 
hdfs dfs -ls /user/root/input/

#adding file to hadoop
docker cp mapper2.py namenode:/CC/s2/
docker cp mapper.py namenode:mapper.py
docker cp reducer.py namenode:reducer.py

#putting in folder
hadoop fs -put mapper.py /user/root/input/
hadoop fs -put reducer.py /user/root/input/

#running
hadoop jar /opt/hadoop-3.2.1/share/hadoop/tools/lib/hadoop-streaming-3.2.1.jar \
    -file  mapper.py \
    -mapper "python3 mapper.py" \
    -file  reducer.py\
    -reducer "python3 reducer.py" \
    -input /user/root/input/dataset.csv \
    -output /CC/ms/outputs0 \

hadoop jar /opt/hadoop-3.2.1/share/hadoop/tools/lib/hadoop-streaming-3.2.1.jar \
    -file  mapper2.py \
    -mapper "python3 mapper2.py" \
    -file  reducer2.py\
    -reducer "python3 reducer2.py" \
    -input /user/root/input/dataset.csv \
    -output /CC/s2222/outputs0 \


#jar
/opt/hadoop-3.2.1/share/hadoop/tools/lib/hadoop-streaming-3.2.1.jar

#output
hdfs dfs -cat /CC/s2222/outputs0/part-00000
